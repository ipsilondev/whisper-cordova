syntax = "proto3";

package xla.gpu;

import "tensorflow/compiler/xla/stream_executor/dnn.proto";
import "tensorflow/compiler/xla/xla_data.proto";

// Backend configs for XLA:GPU.
//
// These are metadata that the GPU backend attaches to HloInstructions and later
// uses during e.g. codegen.
//
// Remember that proto3 doesn't give clients a way to tell the difference
// between a field not being present and a field having the default value.
// Choose your defaults carefully.
//
// No guarantee is made about the stability of these protos.
//
// See HloInstruction::backend_config() for more info.

// Backend config for a convolution that runs through cudnn.
message CudnnConvBackendConfig {
  reserved 1, 2;

  // Opaque algorithm number and tuning knobs chosen for this conv.
  stream_executor.dnn.AlgorithmProto algorithm = 6;

  // The scaling factor multiplied with the convolution result.
  double conv_result_scale = 4;

  // Below are the fields related to cuDNN's fused convolution. Refer to
  // GpuConvParams for their meanings.

  // The requested activation (e.g. relu) after the convolution. It is with type
  // stream_executor::dnn::ActivationMode.
  int64 activation_mode = 3;

  // The scaling factor multiplied with the side input. If no side input buffer
  // is provided, this field must be 0.
  double side_input_scale = 5;

  // If the filter (and bias, if present) have been reordered, set this flag.
  // It's placed into a `oneof` block to skip the serialization when not set.
  oneof filter_and_bias_reordering_oneof {
    // cuDNN int8x32 vectorized convolutions (NCHW_VECT_C data layout) can be
    // optimized by reordering the filter and bias (if present). The logical
    // layout stays the same, but the data is shuffled in a way that is
    // compatible with NVidia's IMMA instruction (sm75+).
    bool reordered_int8_nchw_vect = 7;
  }
}

// Backend config for the GEMM operation running through cuBLAS.
message GemmBackendConfig {
  // Opaque optional algorithm number. No chosen number indicates that a
  // different cuBLAS API will be used, which does not allow for choosing an
  // algorithm.
  oneof algorithm {
    int64 selected_algorithm = 1;
  }

  double alpha_real = 2;
  double alpha_imag = 9;

  double beta = 3;

  xla.DotDimensionNumbers dot_dimension_numbers = 7;

  xla.PrecisionConfig precision_config = 12;

  // cublasLt matmul epilogue.
  enum Epilogue {
    DEFAULT = 0;
    BIAS = 1;
    RELU = 2;
    BIAS_RELU = 3;
    GELU = 4;
    GELU_AUX = 5;
    BIAS_GELU = 6;
    BIAS_GELU_AUX = 7;
  }

  Epilogue epilogue = 13;
}

// Backend config for bitcast operation generated from MLIR MHLO dialect.
message BitcastBackendConfig {
  LayoutProto source_layout = 1;
  LayoutProto result_layout = 2;
}
